{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfd050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the day file\n",
    "file_path = r'E:\\Box\\Modeling and Surveys\\Surveys\\Travel Diary Survey\\BATS_2023\\Versioned_Data\\PreWeight_PreLink_MonToSun_20250610\\day.csv'\n",
    "day_df = pd.read_csv(file_path)\n",
    "\n",
    "# check number of unique households filtering\n",
    "unique_households_before = day_df[['hh_id']].drop_duplicates().shape[0]\n",
    "\n",
    "# Filter records where hh_day_complete == 1\n",
    "filtered_day_df = day_df[day_df['hh_day_complete'] == 1]\n",
    "\n",
    "# Count unique combinations of hh_id and day_num\n",
    "unique_household_days   = filtered_day_df[['hh_id', 'day_num']].drop_duplicates().shape[0]\n",
    "unique_households_after = filtered_day_df[['hh_id']].drop_duplicates().shape[0]\n",
    "\n",
    "print(f\"Number of person-days before filtering: {len(day_df)}\")\n",
    "print(f\"Number of unique hh_id before filtering: {unique_households_before}\")\n",
    "print(f\"Number of person-days after filtering (hh_day_complete==1): {len(filtered_day_df)}\")\n",
    "print(f\"Number of unique hh_id after filtering: {unique_households_after}\")\n",
    "print(f\"Number of unique (hh_id, day_num) combinations: {unique_household_days}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837aedc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse day_df to hh_day_df\n",
    "hh_day_df = filtered_day_df[['hh_id', 'day_num']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nCollapsed day_df to hh_day_df: {hh_day_df.shape}\")\n",
    "\n",
    "# Read the incentives file\n",
    "incentives_file_path = r'E:\\Box\\Modeling and Surveys\\Surveys\\Travel Diary Survey\\BATS_2023\\MTC_RSG_Partner Repository\\5.Deliverables\\Task 5 - Sample Plan\\incentives_disaggregate.xlsx'\n",
    "incentives_df = pd.read_excel(incentives_file_path, sheet_name='Sheet1')\n",
    "\n",
    "print(f\"Incentives dataframe shape: {incentives_df.shape}\")\n",
    "print(f\"Incentives columns: {list(incentives_df.columns)}\")\n",
    "\n",
    "# Join the incentives data to the collapsed dataframe\n",
    "merged_df = hh_day_df.merge(incentives_df, on='hh_id', how='left')\n",
    "\n",
    "print(f\"\\nMerged dataframe shape: {merged_df.shape}\")\n",
    "print(f\"Number of households with incentive data: {merged_df['hh_id'].nunique()}\")\n",
    "print(f\"Number of households without incentive data (nulls): {merged_df.isnull().any(axis=1).sum()}\")\n",
    "\n",
    "# Count records grouped by signup_status\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"COUNT OF RECORDS BY SIGNUP_STATUS:\")\n",
    "print(\"=\"*50)\n",
    "signup_counts = merged_df['signup_status'].value_counts(dropna=False)\n",
    "print(signup_counts)\n",
    "\n",
    "print(f\"\\nTotal records: {signup_counts.sum()}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NetworkWrangler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
