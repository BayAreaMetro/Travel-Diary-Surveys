{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9b83874",
   "metadata": {},
   "source": [
    "# BATS 2023: Understanding Race/Ethnicity Question Design Issues\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook analyzes free-text responses in the `race_other` field to understand **how survey participants feel about the race/ethnicity questions** and identify opportunities to improve question design.\n",
    "\n",
    "**Key Questions:**\n",
    "- What identities are people writing in that don't fit the provided checkboxes?\n",
    "- Are people confused about the difference between race and ethnicity?\n",
    "- What patterns suggest the current categories are inadequate?\n",
    "- What feedback can inform better question design for future surveys?\n",
    "\n",
    "## Background\n",
    "\n",
    "The BATS 2023 survey asks about race using a \"select all that apply\" format with these checkboxes:\n",
    "- `race_1`: White\n",
    "- `race_2`: Black or African American  \n",
    "- `race_3`: Asian\n",
    "- `race_4`: American Indian or Alaska Native\n",
    "- `race_5`: Native Hawaiian or Pacific Islander\n",
    "- `race_997`: Other race (with free-text field `race_other`)\n",
    "- `race_999`: Prefer not to answer\n",
    "\n",
    "This follows standard US Census categories, but the free-text responses suggest some participants don't identify with these options.\n",
    "\n",
    "**This analysis is NOT about mapping responses to existing categories** - it's about understanding what's missing or confusing about the current question structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9a93a2",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4a88aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00856ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\schildress\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\schildress\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from collections import Counter\n",
    "from nltk import bigrams\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "# Data paths\n",
    "DATA_DIR = Path(r\"C:\\Box\\Modeling and Surveys\\Surveys\\Travel Diary Survey\\BATS_2023\\Versioned_Data\\PreWeight_PreLink_MonToSun_20250610\")\n",
    "DATASET_GUIDE = \"bats_dataset_guide.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af80c59a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17188, 207)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_file = DATA_DIR / \"person.csv\"\n",
    "\n",
    "person_df = pd.read_csv(person_file)\n",
    "person_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce5e03a",
   "metadata": {},
   "source": [
    "## 2. Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0859da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Race-related columns:\n",
      "  race_1\n",
      "  race_2\n",
      "  race_3\n",
      "  race_4\n",
      "  race_5\n",
      "  race_997\n",
      "  race_999\n",
      "  race_other\n"
     ]
    }
   ],
   "source": [
    "# Check race-related columns\n",
    "race_cols = [col for col in person_df.columns if 'race' in col.lower()]\n",
    "print(\"Race-related columns:\")\n",
    "for col in race_cols:\n",
    "    print(f\"  {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be6b5122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total persons: 17188\n",
      "race_other not null: 469\n",
      "race_other is null: 16719\n",
      "\n",
      "Percentage with race_other: 2.73%\n"
     ]
    }
   ],
   "source": [
    "# Examine race_other field\n",
    "print(f\"Total persons: {len(person_df)}\")\n",
    "print(f\"race_other not null: {person_df['race_other'].notna().sum()}\")\n",
    "print(f\"race_other is null: {person_df['race_other'].isna().sum()}\")\n",
    "print(f\"\\nPercentage with race_other: {person_df['race_other'].notna().sum() / len(person_df) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "821acb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race_997 appears to be checked (non-zero): 5151\n",
      "\n",
      "race_997 checked AND race_other filled: 469\n",
      "race_997 checked BUT race_other empty: 4682\n",
      "race_997 not checked BUT race_other filled: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if race_997 (Other race) was selected\n",
    "# Note: Need to investigate the coding scheme first!\n",
    "if 'race_997' in person_df.columns:\n",
    "    # Count non-null, non-zero values (assuming checked = some non-zero value)\n",
    "    race_997_checked = person_df['race_997'].notna() & (person_df['race_997'] != 0)\n",
    "    print(f\"race_997 appears to be checked (non-zero): {race_997_checked.sum()}\")\n",
    "    \n",
    "    # Check alignment with race_other field\n",
    "    has_race_other = person_df['race_other'].notna()\n",
    "    print(f\"\\nrace_997 checked AND race_other filled: {(race_997_checked & has_race_other).sum()}\")\n",
    "    print(f\"race_997 checked BUT race_other empty: {(race_997_checked & ~has_race_other).sum()}\")\n",
    "    print(f\"race_997 not checked BUT race_other filled: {(~race_997_checked & has_race_other).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4252d843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in race_997:\n",
      "race_997\n",
      "0      12037\n",
      "1        469\n",
      "995     4682\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data type: int64\n",
      "Min: 0\n",
      "Max: 995\n",
      "\n",
      "Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# Investigate race_997 coding - what values does it actually contain?\n",
    "if 'race_997' in person_df.columns:\n",
    "    print(\"Unique values in race_997:\")\n",
    "    print(person_df['race_997'].value_counts(dropna=False).sort_index())\n",
    "    print(f\"\\nData type: {person_df['race_997'].dtype}\")\n",
    "    print(f\"Min: {person_df['race_997'].min()}\")\n",
    "    print(f\"Max: {person_df['race_997'].max()}\")\n",
    "    print(f\"\\nMissing values: {person_df['race_997'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a76a072b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample values from race columns (first 10 rows):\n",
      "   race_1  race_2  race_3  race_4  race_5  race_997  race_999\n",
      "0       0       0       0       0       1         0         0\n",
      "1       0       0       0       0       0         1         0\n",
      "2     995     995     995     995     995       995       995\n",
      "3       0       0       1       0       0         0         0\n",
      "4     995     995     995     995     995       995       995\n",
      "5     995     995     995     995     995       995       995\n",
      "6       0       0       0       0       0         0         1\n",
      "7       0       0       0       0       0         0         1\n",
      "8       0       0       0       0       1         0         0\n",
      "9     995     995     995     995     995       995       995\n",
      "\n",
      "==================================================\n",
      "Value distributions for each race column:\n",
      "==================================================\n",
      "\n",
      "race_1:\n",
      "race_1\n",
      "0      11950\n",
      "995     4682\n",
      "1        556\n",
      "Name: count, dtype: int64\n",
      "\n",
      "race_2:\n",
      "race_2\n",
      "0      12339\n",
      "995     4682\n",
      "1        167\n",
      "Name: count, dtype: int64\n",
      "\n",
      "race_3:\n",
      "race_3\n",
      "0      8368\n",
      "995    4682\n",
      "1      4138\n",
      "Name: count, dtype: int64\n",
      "\n",
      "race_4:\n",
      "race_4\n",
      "0      12379\n",
      "995     4682\n",
      "1        127\n",
      "Name: count, dtype: int64\n",
      "\n",
      "race_5:\n",
      "race_5\n",
      "1      6513\n",
      "0      5993\n",
      "995    4682\n",
      "Name: count, dtype: int64\n",
      "\n",
      "race_997:\n",
      "race_997\n",
      "0      12037\n",
      "995     4682\n",
      "1        469\n",
      "Name: count, dtype: int64\n",
      "\n",
      "race_999:\n",
      "race_999\n",
      "0      11290\n",
      "995     4682\n",
      "1       1216\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check all race columns to understand the coding scheme\n",
    "race_checkbox_cols = ['race_1', 'race_2', 'race_3', 'race_4', 'race_5', 'race_997', 'race_999']\n",
    "available_cols = [col for col in race_checkbox_cols if col in person_df.columns]\n",
    "\n",
    "print(\"Sample values from race columns (first 10 rows):\")\n",
    "print(person_df[available_cols].head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Value distributions for each race column:\")\n",
    "print(\"=\"*50)\n",
    "for col in available_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(person_df[col].value_counts(dropna=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f87f8b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 Hispanic/ethnicity columns:\n",
      "  ethnicity_1\n",
      "  ethnicity_2\n",
      "  ethnicity_3\n",
      "  ethnicity_4\n",
      "  ethnicity_997\n",
      "  ethnicity_999\n",
      "  ethnicity_other\n"
     ]
    }
   ],
   "source": [
    "# What ethnicity/Hispanic columns exist in the dataset?\n",
    "hisp_cols = [col for col in person_df.columns if 'hisp' in col.lower() or 'ethn' in col.lower()]\n",
    "print(f\"Found {len(hisp_cols)} Hispanic/ethnicity columns:\")\n",
    "for col in sorted(hisp_cols):\n",
    "    print(f\"  {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea7b7c3",
   "metadata": {},
   "source": [
    "## Key Finding: Ethnicity Questions Exist Separately\n",
    "\n",
    "The survey DOES ask about ethnicity/Hispanic origin separately from race. However, many respondents still wrote \"Hispanic\" or \"Latino\" in the race_other field. This suggests:\n",
    "\n",
    "1. **People might not be reaching the ethnicity question** (question ordering issue)\n",
    "2. **The distinction between race and ethnicity is unclear** (question design issue)  \n",
    "3. **Hispanic/Latino identity feels more salient than race categories** for many respondents\n",
    "\n",
    "Let's investigate what ethnicity categories are offered and how often they're used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e598a0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethnicity checkbox distributions:\n",
      "==================================================\n",
      "\n",
      "ethnicity_1: 10258 selected out of 12506 (82.0%)\n",
      "\n",
      "ethnicity_2: 705 selected out of 12506 (5.6%)\n",
      "\n",
      "ethnicity_3: 72 selected out of 12506 (0.6%)\n",
      "\n",
      "ethnicity_4: 37 selected out of 12506 (0.3%)\n",
      "\n",
      "ethnicity_997: 441 selected out of 12506 (3.5%)\n",
      "\n",
      "ethnicity_999: 1060 selected out of 12506 (8.5%)\n",
      "\n",
      "==================================================\n",
      "\n",
      "ethnicity_other responses: 440\n"
     ]
    }
   ],
   "source": [
    "# Show distribution of ethnicity checkboxes (same 0/1/995 coding as race)\n",
    "print(\"Ethnicity checkbox distributions:\")\n",
    "print(\"=\"*50)\n",
    "for col in ['ethnicity_1', 'ethnicity_2', 'ethnicity_3', 'ethnicity_4', 'ethnicity_997', 'ethnicity_999']:\n",
    "    if col in person_df.columns:\n",
    "        checked = (person_df[col] == 1).sum()\n",
    "        total = (person_df[col].notna() & (person_df[col] != 995)).sum()\n",
    "        print(f\"\\n{col}: {checked} selected out of {total} ({checked/total*100:.1f}%)\")\n",
    "        \n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"\\nethnicity_other responses: {person_df['ethnicity_other'].notna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73650e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 30 ethnicity_other responses:\n",
      "ethnicity_other\n",
      "Spanish              13\n",
      "Colombian            10\n",
      "Spanish               9\n",
      "Spain                 7\n",
      "peruvian              6\n",
      "Nicaraguan            6\n",
      "Peruvian              6\n",
      "Colombian             6\n",
      "El Salvador           5\n",
      "Guatemalan            5\n",
      "Spain                 5\n",
      "Brazilian             4\n",
      "Peruvian              4\n",
      "Portuguese            4\n",
      "Nicaragua             4\n",
      "Argentina             3\n",
      "Argentinian           3\n",
      "Brazilian             3\n",
      "South American        3\n",
      "Central America       3\n",
      "Nicaraguan            3\n",
      "Peruvian\\n            3\n",
      "Central American      3\n",
      "El Salvador           3\n",
      "Salvadoran            3\n",
      "spanish               2\n",
      "Chilean               2\n",
      "Costa Rican           2\n",
      "Panamanian            2\n",
      "Salvadoran            2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# What did people write in ethnicity_other?\n",
    "print(\"Top 30 ethnicity_other responses:\")\n",
    "print(person_df['ethnicity_other'].value_counts().head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fe9f37",
   "metadata": {},
   "source": [
    "## Survey Design Analysis: What's Not Working?\n",
    "\n",
    "Let's analyze **survey design issues** revealed by the free-text responses in race_other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa8e3a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize race_other responses by theme to identify missing categories\n",
    "def categorize_race_other(text):\n",
    "    \"\"\"Categorize free-text responses by identity theme\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    \n",
    "    text_lower = str(text).lower().strip()\n",
    "    \n",
    "    # Hispanic/Latino\n",
    "    hispanic_keywords = ['hispanic', 'latino', 'latina', 'latinx', 'mexican', 'puerto rican',\n",
    "                          'salvadoran', 'guatemalan', 'colombian', 'peruvian', 'nicaraguan',\n",
    "                          'latin', 'mestizo', 'chicano', 'central american', 'south american']\n",
    "    if any(kw in text_lower for kw in hispanic_keywords):\n",
    "        return 'Hispanic/Latino'\n",
    "    \n",
    "    # Middle Eastern / North African (MENA)\n",
    "    mena_keywords = ['middle eastern', 'middle east', 'arab', 'persian', 'iranian', 'lebanese',\n",
    "                      'egyptian', 'moroccan', 'turkish', 'armenian', 'syrian', 'iraqi', 'jewish']\n",
    "    if any(kw in text_lower for kw in mena_keywords):\n",
    "        return 'Middle Eastern / North African'\n",
    "    \n",
    "    # Multiracial / Mixed\n",
    "    mixed_keywords = ['mixed', 'multi', 'biracial', 'hapa', 'half']\n",
    "    if any(kw in text_lower for kw in mixed_keywords):\n",
    "        return 'Multiracial / Mixed'\n",
    "    \n",
    "    # South Asian (often written as \"Indian\" which Census classifies as Asian but people may not identify that way)\n",
    "    south_asian_keywords = ['indian', 'india', 'pakistani', 'bangladesh', 'sri lanka', 'nepal',\n",
    "                             'south asian', 'desi']\n",
    "    if any(kw in text_lower for kw in south_asian_keywords):\n",
    "        return 'South Asian'\n",
    "    \n",
    "    # Protest / Philosophical responses\n",
    "    protest_keywords = ['human', 'american', 'person', 'prefer not', 'none', 'n/a', 'na', 'no']\n",
    "    if any(kw in text_lower for kw in protest_keywords):\n",
    "        return 'Protest / Decline to state'\n",
    "    \n",
    "    # European nationality (confusion between nationality and race)\n",
    "    european_keywords = ['european', 'italian', 'irish', 'german', 'french', 'english', \n",
    "                          'scottish', 'polish', 'russian', 'scandinavian', 'caucasian']\n",
    "    if any(kw in text_lower for kw in european_keywords):\n",
    "        return 'European ancestry / White'\n",
    "    \n",
    "    return 'Other / Unclear'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415fe709",
   "metadata": {},
   "source": [
    "### 2. Middle Eastern / North African (MENA) - Not Represented\n",
    "\n",
    "**Finding:** 53 people (11% of race_other) wrote Middle Eastern or North African identities.\n",
    "\n",
    "**The Problem:** US Census classifies MENA as \"White,\" but many MENA individuals don't identify that way. The current categories force them to:\n",
    "- Check \"White\" (doesn't feel accurate)\n",
    "- Check \"Other race\" and write in (what they did)\n",
    "- Skip the question\n",
    "\n",
    "**Examples:** Middle Eastern, Arab, Persian, Iranian, Jewish (ethnic), Lebanese, Egyptian, Turkish, Armenian\n",
    "\n",
    "**Recommendation:** Consider adding \"Middle Eastern or North African\" as a distinct race category. This has been proposed for the US Census but not yet adopted. For Bay Area surveys, MENA is a significant population that deserves representation.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Multiracial / Mixed Identity - Limited Options\n",
    "\n",
    "**Finding:** 35 people (7% wrote) \"mixed,\" \"multiracial,\" \"biracial,\" or similar terms.\n",
    "\n",
    "**The problem:** While the survey allows \"select all that apply,\" some people want to explicitly identify as mixed/multiracial rather than checking multiple boxes. The free-text lets them express this.\n",
    "\n",
    "**Examples:** mixed, mixed race, biracial, hapa, half and half\n",
    "\n",
    "**Recommendation:** Consider whether \"Multiracial\" should be its own checkbox option, or if \"select all that apply\" sufficiently captures these identities. Ask mixed-race people how they prefer to answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ec27e",
   "metadata": {},
   "source": [
    "## Summary: Recommendations for Survey Design\n",
    "\n",
    "Based on 469 free-text responses in race_other, here are the key issues and recommendations:\n",
    "\n",
    "### Top 3 Issues\n",
    "\n",
    "**1. Hispanic/Latino Identity (46% of responses)**\n",
    "- Problem: Respondents don't identify with standard race categories (White, Black, Asian)  \n",
    "- Current approach: Separate race + ethnicity questions following US Census\n",
    "- Consider: Offering \"Hispanic/Latino\" as a race option, or using combined race/ethnicity question\n",
    "- Test: Ask Hispanic respondents how they prefer to identify\n",
    "\n",
    "**2. Middle Eastern / North African - Missing Category (11%)**\n",
    "- Problem: MENA individuals are classified as \"White\" but many don't identify that way\n",
    "- Consider: Adding \"Middle Eastern or North African\" as distinct race category\n",
    "- Note: This is increasingly recognized as a needed category (proposed for US Census)\n",
    "\n",
    "**3. Asian Subcategories - Too Broad (6% specifically South Asian)**\n",
    "- Problem: \"Asian\" encompasses East Asian, Southeast Asian, South Asian - very different identities\n",
    "- Consider: Disaggregating into subcategories, especially given Bay Area's large Asian population\n",
    "- Note: Providing specificity shows respect for community diversity\n",
    "\n",
    "### Secondary Issues\n",
    "\n",
    "**Multiracial Identity (7%):** Some want explicit \"Multiracial/Mixed\" option beyond \"select all\"\n",
    "\n",
    "**Conceptual Confusion:** Many conflate race, ethnicity, nationality, ancestry - clearer guidance needed\n",
    "\n",
    "**Protest Responses:** 11% declined to state in race_other (vs. 10% who checked \"Prefer not to answer\") - suggests discomfort with question\n",
    "\n",
    "### Process Recommendations\n",
    "\n",
    "1. **User Testing:** Conduct cognitive interviews with diverse respondents about how they interpret the race/ethnicity questions\n",
    "2. **Question Ordering:** Test whether asking ethnicity before or after race affects response patterns  \n",
    "3. **International Context:** Consider whether US Census categories are appropriate for diverse Bay Area population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de944294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUMMARY: Identity Categories Missing from Current Race Question\n",
      "================================================================================\n",
      "             Identity Category  Count  Percentage of race_other  Percentage of all respondents\n",
      "               Hispanic/Latino    218                      46.5                           1.74\n",
      "               Other / Unclear     64                      13.6                           0.51\n",
      "Middle Eastern / North African     53                      11.3                           0.42\n",
      "    Protest / Decline to state     50                      10.7                           0.40\n",
      "           Multiracial / Mixed     35                       7.5                           0.28\n",
      "                   South Asian     28                       6.0                           0.22\n",
      "     European ancestry / White     21                       4.5                           0.17\n",
      "================================================================================\n",
      "\n",
      "Total race_other responses: 469\n",
      "Total survey respondents: 12,506\n",
      "Percent using race_other field: 3.8%\n"
     ]
    }
   ],
   "source": [
    "# Create summary table for reporting\n",
    "summary_df = race_other_df['category'].value_counts().reset_index()\n",
    "summary_df.columns = ['Identity Category', 'Count']\n",
    "summary_df['Percentage of race_other'] = (summary_df['Count'] / len(race_other_df) * 100).round(1)\n",
    "summary_df['Percentage of all respondents'] = (summary_df['Count'] / 12506 * 100).round(2)\n",
    "\n",
    "print(\"\\nSUMMARY: Identity Categories Missing from Current Race Question\")\n",
    "print(\"=\"*80)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal race_other responses: {len(race_other_df)}\")\n",
    "print(f\"Total survey respondents: 12,506\")\n",
    "print(f\"Percent using race_other field: {len(race_other_df)/12506*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957b83ce",
   "metadata": {},
   "source": [
    "### 4. South Asian Identity - \"Asian\" Feels Too Broad\n",
    "\n",
    "**Finding:** 28 people (6%) specifically wrote \"Indian,\" \"South Asian,\" or \"Desi.\"\n",
    "\n",
    "**The Problem:** While Census classifies all Asians together, people from South Asia (Indian subcontinent) may not identify with or feel represented by the broad \"Asian\" category, which often connotes East Asian in American English.\n",
    "\n",
    "**Examples:** Indian, Asian Indian, South Asian, Desi\n",
    "\n",
    "**Recommendation:** Consider disaggregating \"Asian\" into subcategories:\n",
    "- East Asian (Chinese, Japanese, Korean, etc.)\n",
    "- Southeast Asian (Vietnamese, Filipino, Thai, etc.)  \n",
    "- South Asian (Indian, Pakistani, Bangladeshi, etc.)\n",
    "\n",
    "Or at minimum, communicate clearly that \"Asian\" includes all of Asia.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Confusion: Nationality vs. Race vs. Ethnicity\n",
    "\n",
    "**Finding:** Many responses show confusion between nationality (Mexican, Colombian), ethnicity (Hispanic, Latino), and race constructs.\n",
    "\n",
    "**Examples:**\n",
    "- Writing nationalities: \"Mexican,\" \"Colombian,\" \"Guatemalan,\" \"Peruvian\"\n",
    "- Writing ancestries: \"European,\" \"Italian,\" \"German,\" \"Russian\"\n",
    "- Writing religions: \"Jewish,\" \"Ashkenazi\"\n",
    "\n",
    "**The Problem:** The race/ethnicity distinction is a social construct that doesn't map cleanly onto how people understand their own identity. Many people think in terms of national origin, not abstract racial categories.\n",
    "\n",
    "**Recommendation:** \n",
    "- Provide clearer guidance about what \"race\" means in the survey context\n",
    "- Consider whether national origin / ancestry is actually more useful for your analysis\n",
    "- Test alternative question framings: \"How do you describe your racial or ethnic identity?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2554a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLES BY CATEGORY\n",
      "================================================================================\n",
      "\n",
      "Hispanic/Latino (218 responses):\n",
      "  • Mexican\n",
      "\n",
      "  • Latina\n",
      "  • Mexican American and Swedish American\n",
      "  • latino\n",
      "  • Mexicano\n",
      "  • Mexican-American \n",
      "  • Hispanic\n",
      "  • Hispanic\n",
      "\n",
      "Other / Unclear (64 responses):\n",
      "  • brown\n",
      "  • Guatemala\n",
      "  • i'm a bit of a hybrid\n",
      "  • 亚裔\n",
      "  • other\n",
      "  • othet\n",
      "  • h\n",
      "  • asian\n",
      "\n",
      "Middle Eastern / North African (53 responses):\n",
      "  • Middle Eastern\n",
      "  • Jewish/Middle Eastern\n",
      "  • Southwest Asian / Arab\n",
      "  • middle eastern \n",
      "  • Middle eastern \n",
      "  • middle eastern\n",
      "  • Middle Eastern\n",
      "  • middle eastern\n",
      "\n",
      "Protest / Decline to state (50 responses):\n",
      "  • European American\n",
      "  • North African \n",
      "  • West European, Native American.\n",
      "  • Native American\n",
      "  • Human race\n",
      "  • ashkenazi\n",
      "  • white / native american\n",
      "  • filipino, salvadorean \n",
      "\n",
      "Multiracial / Mixed (35 responses):\n",
      "  • mixed races\n",
      "  • mixed race\n",
      "  • mixto , multiracial \n",
      "  • mixed race\n",
      "  • mixed\n",
      "  • I am half salvadorian, a quarter Japanese, and a quarter English. \"English\" stands for Scottish,Irish, and German.\n",
      "  • mixed race\n",
      "  • mixed \n",
      "\n",
      "South Asian (28 responses):\n",
      "  • indian\n",
      "  • Asian Indian\n",
      "  • Eastern  Indian \n",
      "  • South Asian / Pacific Islander\n",
      "  • Asian Indian Pacific islander\n",
      "\n",
      "  • Asian Indian Pacific Islander\n",
      "  • indian\n",
      "  • I'm from a French Island in the Indian Ocean near Madagascar \n",
      "\n",
      "European ancestry / White (21 responses):\n",
      "  • German immigrant \n",
      "  • European\n",
      "  • Caucasian\n",
      "  • Caucasian\n",
      "  • French etc\n",
      "  • European \n",
      "  • Italian blk\n",
      "  • russian-jew\n"
     ]
    }
   ],
   "source": [
    "# Show examples from each category\n",
    "print(\"EXAMPLES BY CATEGORY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for category in race_other_df['category'].value_counts().index:\n",
    "    examples = race_other_df[race_other_df['category'] == category]['race_other'].head(8).tolist()\n",
    "    print(f\"\\n{category} ({race_other_df[race_other_df['category'] == category].shape[0]} responses):\")\n",
    "    for ex in examples:\n",
    "        print(f\"  • {ex}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043eab23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persons with race_other: 469\n",
      "Unique responses: 300\n"
     ]
    }
   ],
   "source": [
    "# Create subset with race_other responses\n",
    "race_other_df = person_df[person_df['race_other'].notna()].copy()\n",
    "\n",
    "print(f\"Persons with race_other: {len(race_other_df)}\")\n",
    "print(f\"Unique responses: {race_other_df['race_other'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f76920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 30 most common race_other responses:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "race_other\n",
       "Hispanic             18\n",
       "Hispanic             15\n",
       "latino               13\n",
       "Latino               12\n",
       "Middle Eastern       10\n",
       "hispanic             10\n",
       "Mexican               9\n",
       "mexican               8\n",
       "Latino                7\n",
       "mixed                 7\n",
       "Latina                6\n",
       "middle eastern        6\n",
       "Mexican\\n             5\n",
       "Mixed                 5\n",
       "indian                4\n",
       "Puerto Rican          4\n",
       "mixed race            4\n",
       "Jewish                4\n",
       "latin                 3\n",
       "middle eastern        3\n",
       "Mexican               3\n",
       "Latinx                3\n",
       "mixed                 3\n",
       "Hispanic\\n            3\n",
       "Latin                 3\n",
       "Mestizo               3\n",
       "Mexicano              2\n",
       "European American     2\n",
       "Native American       2\n",
       "Caucasian             2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most common raw responses\n",
    "print(\"Top 30 most common race_other responses:\")\n",
    "race_other_df['race_other'].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77220ea4",
   "metadata": {},
   "source": [
    "## 3. Text Cleaning and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909ef035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_clean\n",
       "hispanic                         48\n",
       "latino                           38\n",
       "mexican                          27\n",
       "middle eastern                   23\n",
       "mixed                            17\n",
       "indian                            9\n",
       "latina                            8\n",
       "latin                             8\n",
       "jewish                            6\n",
       "mixed race                        5\n",
       "puerto rican                      4\n",
       "asian indian                      4\n",
       "mexican american                  4\n",
       "mestizo                           4\n",
       "mexicano                          3\n",
       "brown                             3\n",
       "latinx                            3\n",
       "asian indian pacific islander     3\n",
       "chinese                           3\n",
       "hispano                           3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean text for analysis\n",
    "race_other_df['text_clean'] = (\n",
    "    race_other_df['race_other']\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r'[^\\w\\s]', '', regex=True)\n",
    ")\n",
    "\n",
    "race_other_df['text_clean'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9c956b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 30 most common words:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hispanic</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mexican</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>latino</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mixed</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>american</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eastern</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>middle</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>indian</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>asian</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>i</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>race</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>white</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>european</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>the</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>italian</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>indigenous</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>native</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>am</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>latin</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>of</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>a</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>spanish</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>latina</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>in</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>jewish</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>my</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>puerto</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rican</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>half</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  count\n",
       "0     hispanic     62\n",
       "1      mexican     56\n",
       "2       latino     49\n",
       "3        mixed     38\n",
       "4          and     35\n",
       "5     american     32\n",
       "6      eastern     28\n",
       "7       middle     27\n",
       "8       indian     24\n",
       "9        asian     21\n",
       "10           i     20\n",
       "11        race     16\n",
       "12       white     16\n",
       "13    european     14\n",
       "14         the     12\n",
       "15     italian     12\n",
       "16  indigenous     12\n",
       "17      native     12\n",
       "18          am     12\n",
       "19       latin     11\n",
       "20          of     10\n",
       "21           a     10\n",
       "22     spanish     10\n",
       "23      latina      9\n",
       "24          in      9\n",
       "25      jewish      9\n",
       "26          my      8\n",
       "27      puerto      8\n",
       "28       rican      8\n",
       "29        half      8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize\n",
    "race_other_df['tokens'] = race_other_df['text_clean'].apply(nltk.word_tokenize)\n",
    "\n",
    "# Single word analysis\n",
    "all_words = []\n",
    "for token_list in race_other_df['tokens']:\n",
    "    all_words.extend(token_list)\n",
    "\n",
    "word_counts = Counter(all_words)\n",
    "print(\"Top 30 most common words:\")\n",
    "pd.DataFrame(word_counts.most_common(30), columns=['word', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31307c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 two-word phrases:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(middle, eastern)</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(i, am)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(mixed, race)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(puerto, rican)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(mexican, american)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(asian, indian)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(native, american)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(mexican, and)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(pacific, islander)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(my, dad)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(in, the)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(and, italian)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(north, african)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(indigenous, mexican)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(indian, pacific)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(asian, and)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(identify, as)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(el, salvador)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(central, asian)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(we, are)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   bigram  count\n",
       "0       (middle, eastern)     25\n",
       "1                 (i, am)     12\n",
       "2           (mixed, race)     11\n",
       "3         (puerto, rican)      8\n",
       "4     (mexican, american)      7\n",
       "5         (asian, indian)      7\n",
       "6      (native, american)      6\n",
       "7          (mexican, and)      4\n",
       "8     (pacific, islander)      4\n",
       "9               (my, dad)      3\n",
       "10              (in, the)      3\n",
       "11         (and, italian)      3\n",
       "12       (north, african)      3\n",
       "13  (indigenous, mexican)      3\n",
       "14      (indian, pacific)      3\n",
       "15           (asian, and)      3\n",
       "16         (identify, as)      3\n",
       "17         (el, salvador)      3\n",
       "18       (central, asian)      3\n",
       "19              (we, are)      3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bigram analysis\n",
    "all_bigrams = []\n",
    "for token_list in race_other_df['tokens']:\n",
    "    all_bigrams.extend(list(bigrams(token_list)))\n",
    "\n",
    "bigram_counts = Counter(all_bigrams)\n",
    "print(\"Top 20 two-word phrases:\")\n",
    "pd.DataFrame(bigram_counts.most_common(20), columns=['bigram', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25a2929",
   "metadata": {},
   "source": [
    "## 4. Language Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae9aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses with non-ASCII characters: 3\n",
      "Percentage: 0.6%\n"
     ]
    }
   ],
   "source": [
    "# Check for non-ASCII characters\n",
    "def has_non_ascii(text):\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    try:\n",
    "        text.encode('ascii')\n",
    "        return False\n",
    "    except UnicodeEncodeError:\n",
    "        return True\n",
    "\n",
    "race_other_df['has_non_ascii'] = race_other_df['race_other'].apply(has_non_ascii)\n",
    "\n",
    "print(f\"Responses with non-ASCII characters: {race_other_df['has_non_ascii'].sum()}\")\n",
    "print(f\"Percentage: {race_other_df['has_non_ascii'].sum() / len(race_other_df) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b408ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examples of non-ASCII responses (3 total):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "race_other\n",
       "亚裔                                    1\n",
       "Indígena Mexica                       1\n",
       "mexicano (nativo y español blanco)    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show non-ASCII examples\n",
    "non_ascii_responses = race_other_df[race_other_df['has_non_ascii']]\n",
    "if len(non_ascii_responses) > 0:\n",
    "    print(f\"\\nExamples of non-ASCII responses ({len(non_ascii_responses)} total):\")\n",
    "    non_ascii_responses['race_other'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2e77a9",
   "metadata": {},
   "source": [
    "## 5. Multi-racial Response Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e374d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of number of race categories selected:\n",
      "num_races_selected\n",
      "1    372\n",
      "2     79\n",
      "3     12\n",
      "4      4\n",
      "6      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Respondents who selected multiple race categories: 97\n",
      "Percentage: 20.7%\n"
     ]
    }
   ],
   "source": [
    "# Check if respondents also selected other race checkboxes\n",
    "race_checkbox_cols = ['race_1', 'race_2', 'race_3', 'race_4', 'race_5', 'race_997', 'race_999']\n",
    "available_race_cols = [col for col in race_checkbox_cols if col in race_other_df.columns]\n",
    "\n",
    "if available_race_cols:\n",
    "    # Count how many race boxes were checked\n",
    "    race_other_df['num_races_selected'] = race_other_df[available_race_cols].sum(axis=1)\n",
    "    \n",
    "    print(\"Distribution of number of race categories selected:\")\n",
    "    print(race_other_df['num_races_selected'].value_counts().sort_index())\n",
    "    \n",
    "    print(f\"\\nRespondents who selected multiple race categories: {(race_other_df['num_races_selected'] > 1).sum()}\")\n",
    "    print(f\"Percentage: {(race_other_df['num_races_selected'] > 1).sum() / len(race_other_df) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ada90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses with multi-racial language: 105\n",
      "Percentage: 22.4%\n",
      "\n",
      "Examples of multi-racial text:\n",
      "race_other\n",
      "mixed                                                                                                                                                                                                                                                                7\n",
      "Mixed                                                                                                                                                                                                                                                                5\n",
      "mixed race                                                                                                                                                                                                                                                           4\n",
      "mixed                                                                                                                                                                                                                                                                3\n",
      "Latino/Hispanic                                                                                                                                                                                                                                                      2\n",
      "Hispanic/Latino                                                                                                                                                                                                                                                      2\n",
      "mixed\\n                                                                                                                                                                                                                                                              2\n",
      "Mexican American and Swedish American                                                                                                                                                                                                                                1\n",
      "Mexican-American                                                                                                                                                                                                                                                     1\n",
      "mixed races                                                                                                                                                                                                                                                          1\n",
      "Latin American maybe -- difficult q for Mexican Americans b/c usually the standard choices provided don't quite seem to make sense.                                                                                                                                  1\n",
      "Jewish/Middle Eastern                                                                                                                                                                                                                                                1\n",
      "Latino, US Born Citizen in San Francisco, At the Presidio Army Base at Letterman General Hospital in 1956. As my Dad was serving in the US Army at the NIKE Missile Faculity in the Marin Headlands - or SF-88 - If it FLIES - It Dies.. That was my Dad's Group.    1\n",
      "Puerto Rican and Italian                                                                                                                                                                                                                                             1\n",
      "Southwest Asian / Arab                                                                                                                                                                                                                                               1\n",
      "mixto , multiracial                                                                                                                                                                                                                                                  1\n",
      "Mixed race, with majority European and some Indigenous Central American background                                                                                                                                                                                   1\n",
      "mexican and puerto rican                                                                                                                                                                                                                                             1\n",
      "I am half salvadorian, a quarter Japanese, and a quarter English. \"English\" stands for Scottish,Irish, and German.                                                                                                                                                   1\n",
      "South Asian / Pacific Islander                                                                                                                                                                                                                                       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Detect multi-racial keywords in free text\n",
    "multi_racial_keywords = ['and', 'half', 'mixed', 'multiracial', 'multi racial', 'biracial', 'bi racial', '/', '-']\n",
    "\n",
    "def contains_multiracial_language(text):\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    text_lower = str(text).lower()\n",
    "    return any(keyword in text_lower for keyword in multi_racial_keywords)\n",
    "\n",
    "race_other_df['has_multiracial_text'] = race_other_df['race_other'].apply(contains_multiracial_language)\n",
    "\n",
    "print(f\"Responses with multi-racial language: {race_other_df['has_multiracial_text'].sum()}\")\n",
    "print(f\"Percentage: {race_other_df['has_multiracial_text'].sum() / len(race_other_df) * 100:.1f}%\")\n",
    "\n",
    "# Examples\n",
    "if race_other_df['has_multiracial_text'].sum() > 0:\n",
    "    print(\"\\nExamples of multi-racial text:\")\n",
    "    print(race_other_df[race_other_df['has_multiracial_text']]['race_other'].value_counts().head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fce124",
   "metadata": {},
   "source": [
    "## Conclusion: What We Learned About Survey Design\n",
    "\n",
    "This analysis examined 469 free-text responses in the race_other field to understand how well the current race/ethnicity questions serve respondents. **The goal was NOT to map responses to existing categories, but to identify what's missing or confusing about the current question design.**\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Hispanic/Latino identity is the #1 issue (46% of responses)**\n",
    "   - Many Hispanic respondents don't identify with the provided race categories\n",
    "   - Even those who correctly answer the ethnicity question still write \"Hispanic\" in race_other\n",
    "   - The two-question format (race + ethnicity) doesn't match how people experience their identity\n",
    "\n",
    "2. **Middle Eastern / North African is not represented (11% of responses)**\n",
    "   - MENA individuals are classified as \"White\" by US Census but many don't identify that way\n",
    "   - This is a significant Bay Area population that deserves distinct representation\n",
    "\n",
    "3. **\"Asian\" is too broad (6% wrote specific South Asian identity)**\n",
    "   - Combining East Asian, Southeast Asian, and South Asian into one category doesn't reflect community diversity\n",
    "   - Consider disaggregating, especially for a region with large Asian population\n",
    "\n",
    "### What to Do Next\n",
    "\n",
    "**Short-term:** Accept that the current categories don't serve everyone well. Use this analysis to inform data interpretation and reporting.\n",
    "\n",
    "**Long-term:** Consider redesigning the race/ethnicity questions for future surveys:\n",
    "- Test combined race/ethnicity questions vs. two separate questions  \n",
    "- Add MENA category\n",
    "- Disaggregate Asian categories\n",
    "- Conduct cognitive interviews with diverse respondents about what question formats work best\n",
    "\n",
    "**Most important:** Recognize that race/ethnicity are social constructs that don't map cleanly onto how everyone understands their identity. The \"wrong\" answers in free-text fields are actually valuable feedback about question design."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bats_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
