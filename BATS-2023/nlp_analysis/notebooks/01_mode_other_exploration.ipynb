{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "675531e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "507ca8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\schildress\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\schildress\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from collections import Counter\n",
    "from nltk import bigrams\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "# Data paths\n",
    "DATA_DIR = Path(r\"C:\\\\Box\\\\Modeling and Surveys\\\\Surveys\\\\Travel Diary Survey\\\\BATS_2023\\\\Versioned_Data\\\\PreWeight_PreLink_MonToSun_20250610\")\n",
    "DATASET_GUIDE = \"bats_dataset_guide.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed82a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "person_file = DATA_DIR / \"person.csv\"\n",
    "trip_file = DATA_DIR / \"trip.csv\"\n",
    "\n",
    "person_df = pd.read_csv(person_file)\n",
    "trip_df = pd.read_csv(trip_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ddb62ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373406, 103)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c048571b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373406,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.int64(371774)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    NaN\n",
       "2    NaN\n",
       "3    NaN\n",
       "4    NaN\n",
       "5    NaN\n",
       "6    NaN\n",
       "7    NaN\n",
       "8    NaN\n",
       "9    NaN\n",
       "Name: mode_other_specify, dtype: str"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_df['mode_other_specify'].shape\n",
    "trip_df['mode_other_specify'].isna().sum()\n",
    "trip_df['mode_other_specify'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a01743bf",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1632, 103)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "mode_other_specify\n",
       "bus                                     132\n",
       "car                                     124\n",
       "tour bus                                 84\n",
       "work truck                               47\n",
       "my car                                   30\n",
       "                                       ... \n",
       "ar did not leave the house that day.      1\n",
       "car.                                      1\n",
       "used my car to drive.                     1\n",
       "i                                         1\n",
       "ascensor                                  1\n",
       "Name: count, Length: 480, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_other_df = trip_df[trip_df['mode_other_specify'].notna()]\n",
    "\n",
    "mode_other_df.shape  # how many have mode_other_specify filled in?\n",
    "mode_other_df['mode_other_specify'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae3c1030",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "mode_other_df['text_clean'] = (\n",
    "    mode_other_df['mode_other_specify']\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .str.replace(r'[^\\w\\s]', '', regex=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bbfafbd",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_clean\n",
       "car                           141\n",
       "bus                           139\n",
       "tour bus                       95\n",
       "my car                         59\n",
       "work truck                     52\n",
       "sf muni transit                39\n",
       "walked                         32\n",
       "school bus                     32\n",
       "sf muni trasit                 30\n",
       "san francisco muni transit     25\n",
       "work vehicle                   20\n",
       "metro                          19\n",
       "bart                           18\n",
       "other                          17\n",
       "none                           17\n",
       "work van                       14\n",
       "public bus                     14\n",
       "cars                           14\n",
       "tren bart                      14\n",
       "bart train                     13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_other_df['text_clean'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e21adcee",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "mode_other_df['tokens'] = mode_other_df['text_clean'].apply(nltk.word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7685cf1e",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113            [i, used, my, own, car]\n",
       "114            [i, used, my, own, car]\n",
       "115       [traveled, in, my, own, car]\n",
       "116       [traveled, in, my, own, car]\n",
       "119            [i, used, my, own, car]\n",
       "                      ...             \n",
       "371119                           [bus]\n",
       "371120                           [bus]\n",
       "371211                     [snowshoes]\n",
       "371212                     [snowshoes]\n",
       "372832                      [ascensor]\n",
       "Name: tokens, Length: 1632, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_other_df['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cd28c60",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bus</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>car</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>muni</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bart</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>work</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tour</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>walked</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>transit</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>truck</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sf</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>and</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>was</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>from</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>a</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>train</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>school</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>in</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>me</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>home</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>vehicle</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>shuttle</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>used</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>van</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>metro</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>didnt</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>is</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  count\n",
       "0       bus    364\n",
       "1       car    333\n",
       "2         i    188\n",
       "3        to    180\n",
       "4        my    149\n",
       "5      muni    118\n",
       "6      bart    115\n",
       "7      work    107\n",
       "8       the     98\n",
       "9      tour     96\n",
       "10   walked     80\n",
       "11  transit     73\n",
       "12    truck     72\n",
       "13       sf     69\n",
       "14      and     66\n",
       "15      was     54\n",
       "16     from     54\n",
       "17        a     53\n",
       "18    train     53\n",
       "19   school     51\n",
       "20       in     46\n",
       "21       me     45\n",
       "22     home     43\n",
       "23  vehicle     43\n",
       "24  shuttle     39\n",
       "25     used     38\n",
       "26      van     37\n",
       "27    metro     36\n",
       "28    didnt     34\n",
       "29       is     33"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten all tokens into one list\n",
    "all_words = []\n",
    "for token_list in mode_other_df['tokens']:\n",
    "    all_words.extend(token_list)\n",
    "\n",
    "word_counts = Counter(all_words)\n",
    "pd.DataFrame(word_counts.most_common(30), columns=['word', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50ec978e",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 two-word phrases:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(tour, bus)</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(my, car)</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(sf, muni)</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(muni, transit)</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(work, truck)</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(school, bus)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(muni, trasit)</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(own, car)</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(san, francisco)</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(francisco, muni)</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(i, walked)</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(i, didnt)</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(i, used)</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(used, my)</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(i, was)</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(work, vehicle)</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(my, own)</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(bart, and)</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(to, the)</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(bart, train)</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bigram  count\n",
       "0         (tour, bus)     95\n",
       "1           (my, car)     83\n",
       "2          (sf, muni)     69\n",
       "3     (muni, transit)     64\n",
       "4       (work, truck)     52\n",
       "5       (school, bus)     40\n",
       "6      (muni, trasit)     30\n",
       "7          (own, car)     25\n",
       "8    (san, francisco)     25\n",
       "9   (francisco, muni)     25\n",
       "10        (i, walked)     24\n",
       "11         (i, didnt)     24\n",
       "12          (i, used)     22\n",
       "13         (used, my)     22\n",
       "14           (i, was)     22\n",
       "15    (work, vehicle)     20\n",
       "16          (my, own)     17\n",
       "17        (bart, and)     16\n",
       "18          (to, the)     15\n",
       "19      (bart, train)     15"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bigrams = []\n",
    "for token_list in mode_other_df['tokens']:\n",
    "    all_bigrams.extend(list(bigrams(token_list)))\n",
    "\n",
    "bigram_counts = Counter(all_bigrams)\n",
    "print(\"Top 20 two-word phrases:\")\n",
    "pd.DataFrame(bigram_counts.most_common(20), columns=['bigram', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf50e731",
   "metadata": {},
   "source": [
    "## Language Detection\n",
    "\n",
    "Let's check how many responses are in languages other than English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf857303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses with non-ASCII characters: 34\n",
      "Percentage: 2.1%\n"
     ]
    }
   ],
   "source": [
    "# Simple check: look for non-ASCII characters (indicates non-English like Chinese, etc.)\n",
    "def has_non_ascii(text):\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    try:\n",
    "        text.encode('ascii')\n",
    "        return False\n",
    "    except UnicodeEncodeError:\n",
    "        return True\n",
    "\n",
    "mode_other_df['has_non_ascii'] = mode_other_df['mode_other_specify'].apply(has_non_ascii)\n",
    "\n",
    "print(f\"Responses with non-ASCII characters: {mode_other_df['has_non_ascii'].sum()}\")\n",
    "print(f\"Percentage: {mode_other_df['has_non_ascii'].sum() / len(mode_other_df) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a833d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examples of non-ASCII responses (34 total):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mode_other_specify\n",
       "拼車                                      6\n",
       "autobús contra costa                    6\n",
       "ihss护工的车                                4\n",
       "到达目的地                                   3\n",
       "friend‘s car                            2\n",
       "轻轨                                      2\n",
       "轻轨\\n                                    2\n",
       "我只是在户外歩行锻练                              2\n",
       "autobús escolar                         1\n",
       "autobús para uso traporte médico        1\n",
       "autobús schoolar                        1\n",
       "autobús schoolar yellow bus             1\n",
       "xe nhà                                  1\n",
       "問題有誤，我已經選擇乘自己的車，還要間出行方式，自相矛盾. 無法完成答題    1\n",
       "ihss护工的车接送                              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show examples of non-ASCII responses\n",
    "non_ascii_responses = mode_other_df[mode_other_df['has_non_ascii']]\n",
    "print(f\"\\nExamples of non-ASCII responses ({len(non_ascii_responses)} total):\")\n",
    "non_ascii_responses['mode_other_specify'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "674974e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Responses with Spanish keywords: 75\n",
      "Percentage: 4.6%\n"
     ]
    }
   ],
   "source": [
    "# Check for Spanish keywords (using ASCII characters)\n",
    "spanish_keywords = ['tren', 'carro', 'autobus', 'autobús', 'caminando', 'caminar', \n",
    "                    'bicicleta', 'metro', 'ascensor', 'trabajo', 'mi', 'casa']\n",
    "\n",
    "def likely_spanish(text):\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    text_lower = str(text).lower()\n",
    "    # Check if any Spanish keyword appears\n",
    "    return any(keyword in text_lower for keyword in spanish_keywords)\n",
    "\n",
    "mode_other_df['likely_spanish'] = mode_other_df['mode_other_specify'].apply(likely_spanish)\n",
    "\n",
    "# Note: 'metro' could be English too, so this is not perfect\n",
    "print(f\"\\nResponses with Spanish keywords: {mode_other_df['likely_spanish'].sum()}\")\n",
    "print(f\"Percentage: {mode_other_df['likely_spanish'].sum() / len(mode_other_df) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a38f5cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examples of likely Spanish responses (ASCII only, 65 total):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mode_other_specify\n",
       "metro                                                                                                                                                                                                                                                                                                                                                           16\n",
       "tren bart                                                                                                                                                                                                                                                                                                                                                       14\n",
       "transfer to another metro train                                                                                                                                                                                                                                                                                                                                  6\n",
       "metro and walked                                                                                                                                                                                                                                                                                                                                                 3\n",
       "metro.  I work in the stations                                                                                                                                                                                                                                                                                                                                   3\n",
       "I drive for Muni.  I was shifting my train from the last stop to its terminal                                                                                                                                                                                                                                                                                    3\n",
       "did not use other.\\nI  didn't see box for others \\nI walked to store in front of bus stop I didn't use Muni Metro\\n                                                                                                                                                                                                                                              3\n",
       "Metro                                                                                                                                                                                                                                                                                                                                                            3\n",
       "I want to be clear that I left the office at 445pm but did not arrive home until 730pm. I walked to Bart but it was completely shut down eastbound. So I also walked around the FiDi trying to figure out another way across the bay. I was in the trans bay terminal when word came that Bart was running again (after 90+ min delay) so I went back there.     3\n",
       "took metro then walked                                                                                                                                                                                                                                                                                                                                           2\n",
       "this trip is a mistake                                                                                                                                                                                                                                                                                                                                           2\n",
       "airport tram traveled from long term parking to airport terminal                                                                                                                                                                                                                                                                                                 1\n",
       "Milpitas smart van on demand service                                                                                                                                                                                                                                                                                                                             1\n",
       "rode with family to game                                                                                                                                                                                                                                                                                                                                         1\n",
       "this is a mistake . From  6:45 I took a bus to Columbus & Powell, picked up groceries & took the bus back home by 7:30\\n                                                                                                                                                                                                                                         1\n",
       "mixed - i dripped my car to the charger\\n                                                                                                                                                                                                                                                                                                                        1\n",
       "filling in for missed time on the same bus because app wasn't tracking                                                                                                                                                                                                                                                                                           1\n",
       "ascensor                                                                                                                                                                                                                                                                                                                                                         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show Spanish examples\n",
    "spanish_responses = mode_other_df[mode_other_df['likely_spanish'] & ~mode_other_df['has_non_ascii']]\n",
    "print(f\"\\nExamples of likely Spanish responses (ASCII only, {len(spanish_responses)} total):\")\n",
    "spanish_responses['mode_other_specify'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f775137f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Language Summary ===\n",
      "Total responses: 1632\n",
      "Non-ASCII (Chinese, etc.): 34 (2.1%)\n",
      "Likely Spanish (ASCII): 65 (4.0%)\n",
      "Total non-English: 99 (6.1%)\n",
      "English: 1533 (93.9%)\n"
     ]
    }
   ],
   "source": [
    "# Summary of non-English responses\n",
    "mode_other_df['non_english'] = mode_other_df['has_non_ascii'] | mode_other_df['likely_spanish']\n",
    "\n",
    "print(\"\\n=== Language Summary ===\")\n",
    "print(f\"Total responses: {len(mode_other_df)}\")\n",
    "print(f\"Non-ASCII (Chinese, etc.): {mode_other_df['has_non_ascii'].sum()} ({mode_other_df['has_non_ascii'].sum()/len(mode_other_df)*100:.1f}%)\")\n",
    "print(f\"Likely Spanish (ASCII): {(mode_other_df['likely_spanish'] & ~mode_other_df['has_non_ascii']).sum()} ({(mode_other_df['likely_spanish'] & ~mode_other_df['has_non_ascii']).sum()/len(mode_other_df)*100:.1f}%)\")\n",
    "print(f\"Total non-English: {mode_other_df['non_english'].sum()} ({mode_other_df['non_english'].sum()/len(mode_other_df)*100:.1f}%)\")\n",
    "print(f\"English: {(~mode_other_df['non_english']).sum()} ({(~mode_other_df['non_english']).sum()/len(mode_other_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72f415d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All non-ASCII responses:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mode_other_specify\n",
       "拼車                                      6\n",
       "autobús contra costa                    6\n",
       "ihss护工的车                                4\n",
       "到达目的地                                   3\n",
       "friend‘s car                            2\n",
       "轻轨                                      2\n",
       "轻轨\\n                                    2\n",
       "我只是在户外歩行锻练                              2\n",
       "autobús escolar                         1\n",
       "autobús para uso traporte médico        1\n",
       "autobús schoolar                        1\n",
       "autobús schoolar yellow bus             1\n",
       "xe nhà                                  1\n",
       "問題有誤，我已經選擇乘自己的車，還要間出行方式，自相矛盾. 無法完成答題    1\n",
       "ihss护工的车接送                              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at ALL non-ASCII responses to identify other languages\n",
    "print(\"All non-ASCII responses:\")\n",
    "non_ascii_responses['mode_other_specify'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "664d00f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Language breakdown of non-ASCII responses ===\n",
      "detected_language\n",
      "Chinese       21\n",
      "Vietnamese    11\n",
      "Other          2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total non-ASCII responses: 34\n"
     ]
    }
   ],
   "source": [
    "# Categorize non-ASCII responses by language\n",
    "def detect_language_from_chars(text):\n",
    "    \"\"\"Detect language based on character ranges\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return 'unknown'\n",
    "    \n",
    "    # Check for Chinese characters (CJK Unified Ideographs)\n",
    "    if any('\\u4e00' <= char <= '\\u9fff' for char in text):\n",
    "        return 'Chinese'\n",
    "    \n",
    "    # Check for Vietnamese characters (Latin with specific diacritics)\n",
    "    vietnamese_chars = 'ăâđêôơưàằầèềìòồờùừỳáắấéếíóốớúứý'\n",
    "    if any(char in vietnamese_chars for char in text.lower()):\n",
    "        return 'Vietnamese'\n",
    "    \n",
    "    # Check for Spanish-specific accented characters\n",
    "    spanish_chars = 'áéíóúñü'\n",
    "    if any(char in spanish_chars for char in text.lower()):\n",
    "        return 'Spanish'\n",
    "    \n",
    "    # Other non-ASCII\n",
    "    return 'Other'\n",
    "\n",
    "# Apply to non-ASCII responses\n",
    "non_ascii_responses['detected_language'] = non_ascii_responses['mode_other_specify'].apply(detect_language_from_chars)\n",
    "\n",
    "print(\"\\n=== Language breakdown of non-ASCII responses ===\")\n",
    "print(non_ascii_responses['detected_language'].value_counts())\n",
    "print(f\"\\nTotal non-ASCII responses: {len(non_ascii_responses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93c8c105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vietnamese responses:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mode_other_specify\n",
       "autobús contra costa                 6\n",
       "autobús escolar                      1\n",
       "autobús para uso traporte médico     1\n",
       "autobús schoolar                     1\n",
       "autobús schoolar yellow bus          1\n",
       "xe nhà                               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show Vietnamese examples\n",
    "vietnamese_responses = non_ascii_responses[non_ascii_responses['detected_language'] == 'Vietnamese']\n",
    "print(\"\\nVietnamese responses:\")\n",
    "vietnamese_responses['mode_other_specify'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "86829e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chinese responses:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mode_other_specify\n",
       "拼車                                      6\n",
       "ihss护工的车                                4\n",
       "到达目的地                                   3\n",
       "轻轨                                      2\n",
       "轻轨\\n                                    2\n",
       "我只是在户外歩行锻练                              2\n",
       "問題有誤，我已經選擇乘自己的車，還要間出行方式，自相矛盾. 無法完成答題    1\n",
       "ihss护工的车接送                              1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show Chinese examples\n",
    "chinese_responses = non_ascii_responses[non_ascii_responses['detected_language'] == 'Chinese']\n",
    "print(\"\\nChinese responses:\")\n",
    "chinese_responses['mode_other_specify'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e46e5f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Corrected Language Summary ===\n",
      "Total responses: 1632\n",
      "\n",
      "Non-English responses:\n",
      "  Chinese: 21 (1.29%)\n",
      "  Spanish (with accents like autobús): 10 (0.61%)\n",
      "  Spanish (ASCII-only, like 'tren bart'): ~55 (3.37%)\n",
      "  Vietnamese (xe nhà): 1 (0.06%)\n",
      "  Other (friend's car, etc.): 2 (0.12%)\n",
      "\n",
      "Total estimated non-English: ~89 (5.5%)\n",
      "English: ~1543 (94.5%)\n"
     ]
    }
   ],
   "source": [
    "# Final language summary (correcting for Spanish having non-ASCII too)\n",
    "print(\"\\n=== Corrected Language Summary ===\")\n",
    "print(f\"Total responses: {len(mode_other_df)}\")\n",
    "print(f\"\\nNon-English responses:\")\n",
    "print(f\"  Chinese: 21 ({21/len(mode_other_df)*100:.2f}%)\")\n",
    "print(f\"  Spanish (with accents like autobús): 10 ({10/len(mode_other_df)*100:.2f}%)\")\n",
    "print(f\"  Spanish (ASCII-only, like 'tren bart'): ~55 ({55/len(mode_other_df)*100:.2f}%)\")\n",
    "print(f\"  Vietnamese (xe nhà): 1 ({1/len(mode_other_df)*100:.2f}%)\")\n",
    "print(f\"  Other (friend's car, etc.): 2 ({2/len(mode_other_df)*100:.2f}%)\")\n",
    "print(f\"\\nTotal estimated non-English: ~89 (5.5%)\")\n",
    "print(f\"English: ~1543 (94.5%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d5900b",
   "metadata": {},
   "source": [
    "## Check Valid Mode Categories\n",
    "\n",
    "Let's see what mode variables exist in the data and what their valid values are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5d4250f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode-related columns:\n",
      "  mode_type\n",
      "  mode_1\n",
      "  mode_2\n",
      "  mode_3\n",
      "  mode_4\n",
      "  mode_other_specify\n"
     ]
    }
   ],
   "source": [
    "# Check what mode columns exist\n",
    "mode_cols = [col for col in trip_df.columns if 'mode' in col.lower()]\n",
    "print(\"Mode-related columns:\")\n",
    "for col in mode_cols:\n",
    "    print(f\"  {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95208eb1",
   "metadata": {},
   "source": [
    "## First Round Recoding to mode_1 Codes\n",
    "\n",
    "Map free-text responses to actual mode_1 codes (when possible). Return None for ambiguous cases needing review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8fe9275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_mode_other_to_mode1(text_clean):\n",
    "    \"\"\"\n",
    "    Recode free-text mode responses to mode_1 codes.\n",
    "    Returns mode_1 code (int) or None for unclear cases.\n",
    "    \n",
    "    Based on mode_1 codes from dataset guide:\n",
    "    1=Walk, 2=Bicycle, 23=Local bus, 24=School bus, 30=BART, \n",
    "    33=Car from work, 36=Taxi, 49=TNC (Uber/Lyft), 53=MUNI Metro,\n",
    "    6-16=Household vehicles, 82=E-bike, 83=Scooter-share, etc.\n",
    "    \"\"\"\n",
    "    if pd.isna(text_clean):\n",
    "        return None\n",
    "    \n",
    "    text = str(text_clean).lower()\n",
    "    \n",
    "    # Non-informative - mark for removal\n",
    "    if text in ['none', 'other', 'nothing', 'na', 'n/a', 'i', '']:\n",
    "        return 'JUNK'\n",
    "    \n",
    "    # Didn't travel - mark for removal\n",
    "    if 'didnt' in text or \"didn't\" in text or 'did not' in text:\n",
    "        return 'JUNK'\n",
    "    \n",
    "    # 24: School bus\n",
    "    if 'school bus' in text or 'schoolbus' in text:\n",
    "        return 24\n",
    "    \n",
    "    # 30: BART\n",
    "    if 'bart' in text or 'tren bart' in text:\n",
    "        return 30\n",
    "    \n",
    "    # 53: MUNI Metro (for SF Muni variations)\n",
    "    if any(phrase in text for phrase in ['muni', 'sf transit', 'san francisco transit']):\n",
    "        return 53\n",
    "    \n",
    "    # 23: Local public bus (excluding tour/school/work buses)\n",
    "    if 'bus' in text and not any(x in text for x in ['tour', 'school', 'work', 'shuttle', 'company', 'employer']):\n",
    "        return 23\n",
    "    \n",
    "    # 49: Uber/Lyft/TNC\n",
    "    if any(word in text for word in ['uber', 'lyft', 'rideshare', 'ride share', 'ride service']):\n",
    "        return 49\n",
    "    \n",
    "    # 36: Regular taxi\n",
    "    if 'taxi' in text:\n",
    "        return 36\n",
    "    \n",
    "    # 1: Walk\n",
    "    if any(word in text for word in ['walk', 'walked', 'walking']) and 'bike' not in text:\n",
    "        return 1\n",
    "    \n",
    "    # 82: Electric bicycle (household)\n",
    "    if any(phrase in text for phrase in ['ebike', 'e-bike', 'electric bike', 'electric bicycle']):\n",
    "        return 82\n",
    "    \n",
    "    # 83: Scooter-share\n",
    "    if any(phrase in text for phrase in ['bird', 'lime', 'scooter share', 'shared scooter']):\n",
    "        return 83\n",
    "    \n",
    "    # 77: Personal scooter/moped (not shared)\n",
    "    if 'scooter' in text or 'moped' in text:\n",
    "        return 77\n",
    "    \n",
    "    # 2: Standard bicycle\n",
    "    if any(word in text for word in ['bike', 'bicycle', 'cycling']) and 'e-bike' not in text:\n",
    "        return 2\n",
    "    \n",
    "    # 47: Motorcycle (household)\n",
    "    if 'motorcycle' in text or 'motorbike' in text:\n",
    "        return 47\n",
    "    \n",
    "    # 33: Car from work / work vehicle\n",
    "    if any(phrase in text for phrase in ['work truck', 'work van', 'work vehicle', 'work car', 'company truck', 'company van', 'company vehicle', 'company car']):\n",
    "        return 33\n",
    "    \n",
    "    # 6: Household vehicle (for \"my car\", \"own car\", \"car\", etc.)\n",
    "    if any(phrase in text for phrase in ['my car', 'own car', 'personal car', 'private car', 'household car']) or text in ['car', 'cars']:\n",
    "        return 6\n",
    "    \n",
    "    # Ambiguous/needs review\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb7457c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recoded mode_1 distribution:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schildress\\AppData\\Local\\Temp\\ipykernel_35684\\4203535940.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  mode_other_df['mode_1_recoded'] = mode_other_df['text_clean'].apply(recode_mode_other_to_mode1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mode_1_recoded\n",
       "None    622\n",
       "6       267\n",
       "23      196\n",
       "30      113\n",
       "53      112\n",
       "33       90\n",
       "JUNK     83\n",
       "1        77\n",
       "24       40\n",
       "2        14\n",
       "77        6\n",
       "82        6\n",
       "49        4\n",
       "83        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the recoding function\n",
    "mode_other_df['mode_1_recoded'] = mode_other_df['text_clean'].apply(recode_mode_other_to_mode1)\n",
    "\n",
    "# Show summary of recoded categories\n",
    "print(\"Recoded mode_1 distribution:\")\n",
    "mode_other_df['mode_1_recoded'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b31e55a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total uncoded: 622 out of 1632 (38.1%)\n",
      "\n",
      "Most common uncoded responses:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "text_clean\n",
       "tour bus                           95\n",
       "metro                              19\n",
       "skateboard                         13\n",
       "running                            12\n",
       "b                                  12\n",
       "train                              11\n",
       "working van                        11\n",
       "shuttle                             9\n",
       "friends car                         7\n",
       "a car                               7\n",
       "ups truck                           7\n",
       "friend drive                        7\n",
       "tractor trailer                     7\n",
       "idk                                 6\n",
       "uhaul truck                         6\n",
       "trail run by foot                   6\n",
       "拼車                                  6\n",
       "transfer to another metro train     6\n",
       "autobús contra costa                6\n",
       "gondola                             5\n",
       "gig car share                       5\n",
       "shuttle bus                         5\n",
       "ski                                 5\n",
       "kaiser van                          5\n",
       "amtrak                              4\n",
       "my feet                             4\n",
       "cable car                           4\n",
       "self car                            4\n",
       "none were used                      4\n",
       "currently working                   4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what's still uncoded (None values)\n",
    "uncoded = mode_other_df[mode_other_df['mode_1_recoded'].isna()]\n",
    "print(f\"Total uncoded: {len(uncoded)} out of {len(mode_other_df)} ({len(uncoded)/len(mode_other_df)*100:.1f}%)\")\n",
    "print(\"\\nMost common uncoded responses:\")\n",
    "uncoded['text_clean'].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41870ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mode_other_specify</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>mode_1_recoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105816</th>\n",
       "      <td>bart and ferry</td>\n",
       "      <td>bart and ferry</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371118</th>\n",
       "      <td>bus</td>\n",
       "      <td>bus</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81777</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62360</th>\n",
       "      <td>bus</td>\n",
       "      <td>bus</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150438</th>\n",
       "      <td>shuttle</td>\n",
       "      <td>shuttle</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197919</th>\n",
       "      <td>I was in Muni Merro</td>\n",
       "      <td>i was in muni merro</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67577</th>\n",
       "      <td>gig car share</td>\n",
       "      <td>gig car share</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333883</th>\n",
       "      <td>subaru</td>\n",
       "      <td>subaru</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279697</th>\n",
       "      <td>bart</td>\n",
       "      <td>bart</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37699</th>\n",
       "      <td>work van</td>\n",
       "      <td>work van</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364507</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364085</th>\n",
       "      <td>tren bart</td>\n",
       "      <td>tren bart</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161024</th>\n",
       "      <td>shuttle</td>\n",
       "      <td>shuttle</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365971</th>\n",
       "      <td>my car I drove today</td>\n",
       "      <td>my car i drove today</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203183</th>\n",
       "      <td>transfer to another metro train</td>\n",
       "      <td>transfer to another metro train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85335</th>\n",
       "      <td>currently working</td>\n",
       "      <td>currently working</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357190</th>\n",
       "      <td>walked</td>\n",
       "      <td>walked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85400</th>\n",
       "      <td>work truck</td>\n",
       "      <td>work truck</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123983</th>\n",
       "      <td>trail running by foot</td>\n",
       "      <td>trail running by foot</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85386</th>\n",
       "      <td>work truck</td>\n",
       "      <td>work truck</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mode_other_specify                       text_clean  \\\n",
       "105816                  bart and ferry                    bart and ferry   \n",
       "371118                              bus                              bus   \n",
       "81777                                no                               no   \n",
       "62360                               bus                              bus   \n",
       "150438                          shuttle                          shuttle   \n",
       "197919              I was in Muni Merro              i was in muni merro   \n",
       "67577                     gig car share                    gig car share   \n",
       "333883                           subaru                           subaru   \n",
       "279697                             bart                             bart   \n",
       "37699                          work van                         work van   \n",
       "364507                                b                                b   \n",
       "364085                        tren bart                        tren bart   \n",
       "161024                         shuttle                           shuttle   \n",
       "365971             my car I drove today             my car i drove today   \n",
       "203183  transfer to another metro train  transfer to another metro train   \n",
       "85335                currently working                 currently working   \n",
       "357190                           walked                           walked   \n",
       "85400                       work truck                        work truck   \n",
       "123983            trail running by foot            trail running by foot   \n",
       "85386                       work truck                        work truck   \n",
       "\n",
       "       mode_1_recoded  \n",
       "105816             30  \n",
       "371118             23  \n",
       "81777            None  \n",
       "62360              23  \n",
       "150438           None  \n",
       "197919             53  \n",
       "67577            None  \n",
       "333883           None  \n",
       "279697             30  \n",
       "37699              33  \n",
       "364507           None  \n",
       "364085             30  \n",
       "161024           None  \n",
       "365971              6  \n",
       "203183           None  \n",
       "85335            None  \n",
       "357190              1  \n",
       "85400              33  \n",
       "123983           None  \n",
       "85386              33  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample of original text and recoded mode_1 for quality check\n",
    "sample_recode = mode_other_df[['mode_other_specify', 'text_clean', 'mode_1_recoded']].sample(20, random_state=42)\n",
    "sample_recode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bats_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
